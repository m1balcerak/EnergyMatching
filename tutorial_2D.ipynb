{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Matching 2D Tutorial\n",
    "This notebook demonstrates how to train an energy-based model with conditional flow matching on a simple 2D dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchcfm.conditional_flow_matching import ExactOptimalTransportConditionalFlowMatcher\n",
    "from torchcfm.utils import sample_8gaussians, sample_moons\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Hyperparameters\n",
    "FLOW_EPOCHS_PHASE1 = 20000\n",
    "FLOW_EPOCHS_PHASE2 = 10000\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 1e-4\n",
    "FLOW_LOSS_WEIGHT = 1.0\n",
    "EBM_LOSS_WEIGHT = 1.0\n",
    "SIGMA = 0.1\n",
    "SAVE_DIR = 'EM_good'\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Model and utilities\n",
    "class PotentialModel(nn.Module):\n",
    "    def __init__(self, dim=2, w=128, time_varying=True):\n",
    "        super().__init__()\n",
    "        self.time_varying = time_varying\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim + (1 if time_varying else 0), w),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(w, w),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(w, w),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(w, w),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(w, 1)\n",
    "        )\n",
    "    def forward(self, x, t=None):\n",
    "        if not self.time_varying:\n",
    "            return self.net(x)\n",
    "        if t is None:\n",
    "            raise ValueError('time_varying=True but t is None.')\n",
    "        if t.dim() == 0:\n",
    "            t = t.expand(x.size(0)).unsqueeze(-1)\n",
    "        elif t.dim() == 1:\n",
    "            if t.size(0) != x.size(0):\n",
    "                t = t.expand(x.size(0)).unsqueeze(-1)\n",
    "            else:\n",
    "                t = t.unsqueeze(-1)\n",
    "        t_clamped = torch.clamp(t, max=0.0)\n",
    "        inp = torch.cat([x, t_clamped], dim=-1)\n",
    "        return self.net(inp)\n",
    "\n",
    "def temperature(t):\n",
    "    if t.dim() == 2 and t.size(1) == 1:\n",
    "        t = t.squeeze(-1)\n",
    "    eps = torch.zeros_like(t)\n",
    "    mask_mid = (t >= 0.8) & (t < 1.0)\n",
    "    eps[mask_mid] = 0.2 * (t[mask_mid] - 0.8) / 0.2\n",
    "    eps[t >= 1.0] = 0.15\n",
    "    return eps\n",
    "\n",
    "def velocity_training(model, x, t):\n",
    "    x = x.detach().requires_grad_(True)\n",
    "    V = model(x, t)\n",
    "    gradV = torch.autograd.grad(V.sum(), x, create_graph=True)[0]\n",
    "    return -gradV\n",
    "\n",
    "def velocity_inference(model, x, t):\n",
    "    with torch.enable_grad():\n",
    "        if not x.requires_grad:\n",
    "            x = x.detach().requires_grad_(True)\n",
    "        V = model(x, t)\n",
    "        gradV = torch.autograd.grad(V.sum(), x, create_graph=False)[0]\n",
    "    return -gradV\n",
    "\n",
    "def gibbs_sampler(model, x_init, t_start, steps=10, dt=0.01):\n",
    "    x = x_init\n",
    "    for step in range(steps):\n",
    "        t_current = t_start + (1 - t_start) * ((step + 1) / steps)\n",
    "        x.requires_grad_(True)\n",
    "        V = model(x, torch.tensor(1.0, device=x.device))\n",
    "        g = torch.autograd.grad(V.sum(), x, create_graph=False)[0]\n",
    "        eps = temperature(t_current)\n",
    "        noise_scale = torch.sqrt(2.0 * eps * dt).unsqueeze(-1)\n",
    "        noise = noise_scale * torch.randn_like(x)\n",
    "        x = (x - g * dt + noise).detach()\n",
    "    return x\n",
    "\n",
    "def simulate_piecewise_length(model, x0, dt=0.01, max_length=4.0):\n",
    "    x = x0\n",
    "    traj = [x0.cpu().numpy()]\n",
    "    times = [0.0]\n",
    "    t_now = 0.0\n",
    "    cum_length = 0.0\n",
    "    device = x0.device\n",
    "    while cum_length < max_length:\n",
    "        t_tensor = torch.tensor([t_now], dtype=x0.dtype, device=device)\n",
    "        g = velocity_inference(model, x, t_tensor)\n",
    "        eps_now = temperature(t_tensor).item()\n",
    "        if t_now < 0.8:\n",
    "            dx = g * dt\n",
    "        else:\n",
    "            noise = torch.sqrt(torch.tensor(2.0 * eps_now * dt, device=device)) * torch.randn_like(x)\n",
    "            dx = g * dt + noise\n",
    "        x = (x + dx).detach()\n",
    "        step_length = torch.norm(dx).item()\n",
    "        cum_length += step_length\n",
    "        t_now += dt\n",
    "        traj.append(x.cpu().numpy())\n",
    "        times.append(t_now)\n",
    "    return np.array(traj), np.array(times)\n",
    "\n",
    "def plot_trajectories_custom(traj):\n",
    "    n = 2000\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(traj[0, :n, 0], traj[0, :n, 1], s=3, alpha=0.8, c='black', marker='s')\n",
    "    plt.scatter(traj[:, :n, 0], traj[:, :n, 1], s=0.2, alpha=0.1, c='olive')\n",
    "    plt.scatter(traj[-1, :n, 0], traj[-1, :n, 1], s=4, alpha=1.0, c='blue', marker='*')\n",
    "    for i in range(10):\n",
    "        plt.plot(traj[:, i, 0], traj[:, i, 1], c='red', linewidth=1.2, alpha=1.0)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    model = PotentialModel(dim=2, w=128, time_varying=True).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    FM = ExactOptimalTransportConditionalFlowMatcher(sigma=SIGMA)\n",
    "    def x0_dist(n):\n",
    "        return sample_8gaussians(n).to(device)\n",
    "    def x1_dist(n):\n",
    "        return sample_moons(n).to(device)\n",
    "    for epoch in range(FLOW_EPOCHS_PHASE1):\n",
    "        optimizer.zero_grad()\n",
    "        x0 = x0_dist(BATCH_SIZE)\n",
    "        x1 = x1_dist(BATCH_SIZE)\n",
    "        t_samp, x_t, u_t = FM.sample_location_and_conditional_flow(x0, x1)\n",
    "        v_pred = velocity_training(model, x_t, t_samp.unsqueeze(-1))\n",
    "        loss_flow = (v_pred - u_t).pow(2).mean()\n",
    "        loss_flow.backward()\n",
    "        optimizer.step()\n",
    "    for epoch in range(FLOW_EPOCHS_PHASE2):\n",
    "        optimizer.zero_grad()\n",
    "        x0 = x0_dist(BATCH_SIZE)\n",
    "        x1 = x1_dist(BATCH_SIZE)\n",
    "        t_flow, x_t_flow, u_t_flow = FM.sample_location_and_conditional_flow(x0, x1)\n",
    "        v_pred_flow = velocity_training(model, x_t_flow, t_flow.unsqueeze(-1))\n",
    "        loss_flow = (v_pred_flow - u_t_flow).pow(2).mean()\n",
    "        x_data = x1_dist(BATCH_SIZE)\n",
    "        Epos = model(x_data, torch.tensor(1.0, device=device)).mean()\n",
    "        half_bs = BATCH_SIZE // 2\n",
    "        x_data_init = x1_dist(half_bs)\n",
    "        x_prior_init = x0_dist(half_bs)\n",
    "        x_init_neg = torch.cat([x_data_init, x_prior_init], dim=0)\n",
    "        t_start = torch.cat([torch.ones(half_bs, device=device), torch.zeros(half_bs, device=device)], dim=0)\n",
    "        x_neg = gibbs_sampler(model, x_init_neg, t_start, steps=200, dt=0.01)\n",
    "        Eneg = model(x_neg, torch.tensor(1.0, device=device)).mean()\n",
    "        loss_ebm = Epos - Eneg\n",
    "        loss = FLOW_LOSS_WEIGHT * loss_flow + EBM_LOSS_WEIGHT * loss_ebm\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    torch.save(model.state_dict(), os.path.join(SAVE_DIR, 'final_V_model.pth'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run training and display results\n",
    "model = train()\n",
    "x_init = sample_8gaussians(1024).to(next(model.parameters()).device)\n",
    "traj_np, times_np = simulate_piecewise_length(model, x_init, dt=0.01, max_length=400)\n",
    "plot_trajectories_custom(traj_np)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
